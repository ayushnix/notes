'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href','section']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/wiki/docs/networking/how-does-dns-work/',title:"How Does DNS Work?",section:"Networking",content:"Introduction #  Here\u0026rsquo;s what I did for hosting my website on GitHub Pages using a custom domain. I\u0026rsquo;ll think about self hosting using a web server on a VPS later.\nGo ahead and purchase a domain from a registrar which offers decent purchase as well as renewal prices on domains. Choose a top-level domain (TLD) which doesn\u0026rsquo;t restrict WHOIS privacy and has DNSSEC. The .com TLD fulfills these criteria but the .in TLD doesn\u0026rsquo;t because it doesn\u0026rsquo;t offer WHOIS privacy. The registrar you choose should also offer WHOIS privacy by default.\nAs on 14th April 2021, CloudFlare doesn\u0026rsquo;t allow you to buy domain names but does allow you to transfer domain names to them but this is a time consuming process. After your domain has been transferred, you\u0026rsquo;ll be locked into CloudFlare\u0026rsquo;s services which can be a bummer. CloudFlare\u0026rsquo;s service has its own set of issues like annoying captchas.\nThe domain name registrar you use would typically offer their own authoritative name servers. You can keep using them if you wish. They might also offer free TLS certificates. You can choose to use them or create your own. For now, we\u0026rsquo;re hosting our website on GitHub Pages and that takes care of the TLS part. If we use a VPS in the future and host our own content on our own web server, that\u0026rsquo;d need messing around with our TLS certs.\nHow Does DNS Work? #  DNS Query and Nameservers #  I\u0026rsquo;ve tried to envision how DNS works, from a bird\u0026rsquo;s eye view, in the following diagram. This probably needs some changes though.\n  Here\u0026rsquo;s what we need to know.\nThe domain, ayushnix.com, is known as the apex domain or the root domain. You might\u0026rsquo;ve come across the www variant on many websites. That\u0026rsquo;s a subdomain, although a special one since it has been in use since the world wide web came along back in 1989.\nYou\u0026rsquo;ll enter ayushnix.com on your web browser and it\u0026rsquo;ll route your query to your local DNS client (also sometimes called a stub resolver). In my case, that\u0026rsquo;s dnscrypt-proxy. People call Unbound a recursive DNS resolver but that\u0026rsquo;s probably only applicable when using Unbound in an actual DNS server setup.\nAt this point, realistically, our query can often be found in the DNS cache of the client we\u0026rsquo;re using and gets resolved almost instantaneously. However, if it isn\u0026rsquo;t, it\u0026rsquo;s forwarded to a recursive DNS server. This can be 1.1.1.1 or 8.8.8.8 or something similar. These recursive DNS servers probably have our query in their cache and if that\u0026rsquo;s the case, we\u0026rsquo;ll get a response shortly. If not, depending on the situation, the recursive DNS you\u0026rsquo;ve queried can either query (recursion!) the\n authoritative nameservers top level domain (TLD) nameservers of .com root nameservers  These nameservers (NS) are mentioned in decreasing order of the probability of being visited.\nIf the recursive DNS we\u0026rsquo;re using doesn\u0026rsquo;t have the A records of ayushnix.com, it\u0026rsquo;ll go to the authoritative NS that ayushnix.com is using. For now, I\u0026rsquo;m using the NS provided by my domain name registrar but one can also use authoritative nameservers provided by Cloudflare or other companies for faster DNS resolution. These authoritative nameservers will provide the required A records and DNS resolution for my website will finish successfully.\nIf the recursive DNS we\u0026rsquo;re using has neither A records nor the authoritative NS records for ayushnix.com, it\u0026rsquo;ll go to the TLD NS of com since I\u0026rsquo;m using the com top level domain. It\u0026rsquo;ll ask for the authoritative NS records of ayushnix.com and upon receiving them, will visit the authoritative NS and get the needed A records.\nIn rare cases, when the recursive DNS we\u0026rsquo;re using doesn\u0026rsquo;t have the address of TLD NS of com, it\u0026rsquo;ll need to go the root nameservers and get the NS records for com. As on April 2021, there are 13 root nameservers maintained by various organizations around the world. Obviously, there are lots of anycast servers behind the scenes. If you want, you can check the list of root nameservers here.\nIt\u0026rsquo;s interesting to note that most queries to root nameservers aren\u0026rsquo;t legitimate but NXDOMAIN queries or other queries due to caching issues. An interesting case was published recently on ArsTechnica which mentioned how a feature in Chrome was generating large amounts of traffic on root nameservers. A detailed blog post was published by Verisign.\nBasically, ISPs often hijack user DNS and show ads for their products on NXDOMAIN pages. Interestingly, Verisign did this themselves with SiteFinder making a wildcard DNS record for all NXDOMAINs in .com and .net TLD and showing ads. Pretty ironic considering this issue with Chrome has been highlighted by Verisign themselves. To stop this bullshit, Chrome started generating random domains to check whether NXDOMAINs were being hijacked and if yes, stopped suggesting the user to visit http://myserver in case the user types myserver in the search plus address bar. However, in case NXDOMAINs weren\u0026rsquo;t being hijacked, Chrome kept checking this and increased load on root nameservers such that more than half all traffic on the root nameserver run by Verisign came from Chrome.\nDNS Resource Records #  DNS resource records are, apparently, often a source of confusion among website owners. I won\u0026rsquo;t document each and every resource record in this section. The A/AAAA record, ALIAS/ANAME record, and the CNAME record are the ones we need to focus on. If you need more information about DNS resource records, go to Cloudflare\u0026rsquo;s Learning Center.\nA Record #  Understanding the A/AAAA record is simple — it holds the IPv4/IPv6 address for a domain. You can use multiple A records for a single domain, kinda like how GitHub Pages tells you to point your apex domain to the following IP addresses and create A records.\n185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 Some websites might use @ to denote the apex domain.\nCNAME Record #  A records are straightforward to use. However, when you\u0026rsquo;re dealing with multiple subdomains, writing A records for each of them isn\u0026rsquo;t the best thing we can do. If the IP addresses that all those A records would point to change, we\u0026rsquo;re gonna have a hard time changing all the A records to reflect those changes.\nTo resolve this issue, we can use CNAME records. A CNAME record must always point to another domain, never to an IP address. The most obvious usage of CNAME records is pointing the www subdomain variant to the apex domain. In my case, I have a CNAME record pointing www.ayushnix.com to ayushnix.com. Here\u0026rsquo;s a truncated output showcasing what I\u0026rsquo;m talking about.\n➜ drill ayushnix.com ;; ANSWER SECTION: ayushnix.com. 3599 IN A 185.199.109.153 ayushnix.com. 3599 IN A 185.199.111.153 ayushnix.com. 3599 IN A 185.199.110.153 ayushnix.com. 3599 IN A 185.199.108.153 ➜ drill www.ayushnix.com ;; ANSWER SECTION: www.ayushnix.com. 2399 IN CNAME ayushnix.github.io. ayushnix.github.io. 2399 IN A 185.199.108.153 ayushnix.github.io. 2399 IN A 185.199.109.153 ayushnix.github.io. 2399 IN A 185.199.110.153 ayushnix.github.io. 2399 IN A 185.199.111.153 A CNAME record can\u0026rsquo;t be used to point the apex domain to another domain. This is a limitation imposed by IETF specifications although some DNS providers, like Cloudflare, don\u0026rsquo;t care about this and allow you to do so. Here\u0026rsquo;s a good article by Cloudflare about this.\n Technically, the root could be a CNAME but the RFCs state that once a record has a CNAME it can\u0026rsquo;t have any other entries associated with it: that\u0026rsquo;s a problem for a root record like example.com because it will often have an MX record (so email gets delivered), an NS record (to find out which nameserver handles the zone) and an SOA record.\n  Because they follow this specification, most authoritative DNS servers won\u0026rsquo;t allow you to include CNAME records at the root. At CloudFlare, we decided to let our users include a CNAME at the root even though we knew it violated the DNS specification. And that worked, most of the time. Unfortunately, there were a handful of edge cases that caused all sorts of problems.\n It\u0026rsquo;d be better if we err on the side of caution here and assume that CNAME records can\u0026rsquo;t be used for anything else (except DNSSEC).\nIt might not be obvious but there\u0026rsquo;s no restriction regarding a CNAME record pointing to another CNAME record or a CNAME record using a subdomain pointing to another different domain. Here\u0026rsquo;s an example.\n$ drill www.skyscanner.net ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, rcode: NOERROR, id: 15722 ;; flags: qr rd ra ; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;; www.skyscanner.net.	IN	A ;; ANSWER SECTION: www.skyscanner.net.	2399	IN	CNAME	www.skyscanner.net.edgekey.net. www.skyscanner.net.edgekey.net.	2399	IN	CNAME	e11001.a.akamaiedge.net. e11001.a.akamaiedge.net.	2399	IN	A	23.213.57.166 Just so we\u0026rsquo;re clear, www.skyscanner.net is a label and www.skyscanner.net.edgekey.net is the CNAME.\nAs shown, www.skyscanner.net points to the CNAME www.skyscanner.net.edgekey.net which in turn points to the CNAME e11001.a.akamaiedge.net which then gives us an IP address.\nHere\u0026rsquo;s one of the advantages of using this setup. What if www.skyscanner.net suddenly starts experiencing too much traffic or wants to use a CDN? In this case, the CNAME of www.skyscanner.net.edgekey.net can be changed to something else like e11316.a.akamaiedge.net when needed and the actual website wouldn\u0026rsquo;t experience any downtime or wouldn\u0026rsquo;t need to change anything.\nThe case of websites using CNAMEs for tracking is interesting to note. Here\u0026rsquo;s an example from AdGuard\u0026rsquo;s cname-trackers repository.\n\u0026quot;tybfxw.puma.com\u0026quot;: \u0026quot;gum.am5.vip.prod.criteo.com\u0026quot; Yes, a web browser without CNAME tracking protection would consider tybfxw.puma.com a first party domain of puma.com but it isn\u0026rsquo;t. It redirects to a subdomain of criteo.com which is a well known advertising company.\nHere\u0026rsquo;s a good blog post about this issue. Basically, use uBlock Origin on Firefox if you want the maximum protection against CNAME tracking.\nALIAS/ANAME Record #  An ALIAS/ANAME record is basically a CNAME record without the limitations and inefficiency of CNAME records.\nCloudflare calls this CNAME flattening.\nIf we use an ALIAS record, we can point ayushnix.com to ayushnix.github.io without any worries. This takes care of the primary limitation of CNAME records.\nTo understand how inefficient CNAME records can be, let\u0026rsquo;s go back to our www.skyscanner.net example mentioned above.\nwww.skyscanner.net. 🠊 www.skyscanner.net.edgekey.net. www.skyscanner.net.edgekey.net. 🠊 e11001.a.akamaiedge.net. e11001.a.akamaiedge.net. 🠊 23.213.57.166 In this case, our recursive NS will start with resolving www.skyscanner.net. After traveling all the way to an authoritative NS and back, it has to visit an authoritative server again to resolve www.skyscanner.net.edgekey.net. This process will be repeated for the resolution of e11001.a.akamaiedge.net. We\u0026rsquo;ve essentially ended up making three DNS queries to resolve a single domain. Obviously, this introduces latency.\nIn contrast, when using an ALIAS record, the authoritative NS of www.skyscanner.net should resolve the underlying domains and return an IP address as the answer to the recursive resolver we\u0026rsquo;re using. As you can imagine, this is relatively faster and the final answer looks like an A record. This can be confirmed by using drill on ayushnix.com.\nOne of the disadvantages of ALIAS mentioned on this blog post tells us that ALIAS records may make CDN efforts worthless because the CDN will respond to the location of the authoritative nameserver, not yours.\n"}),a.add({id:1,href:'/wiki/docs/sysadmin/shell/scripting/',title:"Shell Scripting",section:"Shell",content:"Introduction #  Knowing how to use your shell and being able to write scripts that work across different Unix-like operating systems can be an incredibly important skill. I\u0026rsquo;ve often thought about it as an essential skill that a sysadmin should possess. However, there are various complications when it comes to using shell scripts.\n  although bash is the most popular shell out there, it isn\u0026rsquo;t the standard shell used across all Unix-like systems\nDebian uses dash as its /bin/sh and Alpine, used widely in containers, uses BusyBox which uses its own version of ash. There\u0026rsquo;s tcsh used by FreeBSD and pdksh used by OpenBSD. Needless to say, there are syntactical differences between all of them although scripts written in POSIX sh should probably run reliably across all of these platforms.\n  shell scripts do not have robust error handling features and they can\u0026rsquo;t handle edge cases you didn\u0026rsquo;t think about\nDrew DeVault wrote a blog post about becoming shell literate. A guy on HN rightfully pointed out the flaws in the operation1.\nHere\u0026rsquo;s a blog post about issues when using shell scripts.\n  However, if you know what you\u0026rsquo;re doing, shell scripting using POSIX sh or bash2 can be an incredibly powerful tool in your repertoire. You may or may not have access to Python or Perl in your Unix-like platform or in your container but you will always have a shell.\nWe\u0026rsquo;ll talk about POSIX sh first and then we\u0026rsquo;ll move on to features specific to bash. In case your /bin/sh is symlinked to bash, install dash. There\u0026rsquo;s also mksh which seems to be POSIX compliant and is also used on Android.\nLinter, Formatter, and Testing #  Before we get started with bash shell scripting, install shellcheck.\nWe\u0026rsquo;ll also use shfmt to follow a specific style guide and stick to it. I\u0026rsquo;m using -i 2 -ci -sr -bn options with shfmt. You\u0026rsquo;ll need a plugin like ALE or neomake to use shellcheck and shfmt on neovim.\nI\u0026rsquo;m not sure if bats is helpful. There\u0026rsquo;s also shellspec.\nShell Strict Mode #  This blog post, for better or worse, seems to have popularized strict mode in shell scripting.\nset -e #  First, we have set -e. It\u0026rsquo;s supposed to exit immediately whenever there\u0026rsquo;s an error in a script. However, this doesn\u0026rsquo;t always work as expected. It\u0026rsquo;s not just about set -e not being able to detect certain class of errors. In that case, using it would\u0026rsquo;ve been fine. But, set -e introduces false positives and exits when we may not intend to.\nset -eu count=$(grep -c some-string /usr/bin/pass) # script execution aborts here if [ \u0026#34;${count}\u0026#34; -ne 0 ]; then printf \u0026#39;%s\\n\u0026#39; \u0026#34;something found\u0026#34; else printf \u0026#39;%s\\n\u0026#39; \u0026#34;nothing found\u0026#34; fi In this case, if grep fails to find any match, the exit code becomes non-zero. However, that\u0026rsquo;s fine, because we intend to use it as a test case. But using set -e aborts execution.\nThere are plenty of other examples of unintended behavior when using set -e. As a result, we WON\u0026rsquo;T be using set -e in our scripts.\nset -u #  set -o pipefail #  set -o pipefail doesn\u0026rsquo;t work on POSIX sh  The exit status of a pipeline is the exit status of the last command in the pipeline unless set -o pipefail is enabled in which case the exit status is that of the command which fails first.\nset -C #  We might wanna use set -C to prevent accidental overwriting of files. It\u0026rsquo;d be better to adopt the practice of creating files separately instead of using \u0026gt; to create files as well.\ntrap #  Style Guide #  Google\u0026rsquo;s Shell Style Guide should serve as a good reference but we may not follow everything written there. Using shfmt should help as well.\nGeneral Recommendations #    the following format may be adopted when writing shell scripts\n#!/bin/sh # # BRIEF DESCRIPTION OF WHAT THE SCRIPT DOES # # AUTHOR AND COPYRIGHT INFORMATION IF NEEDED \u0026lt;actual code\u0026gt;   prefer using built-in methods rather than external programs\nsh, and particularly bash, have a lot of built-in methods that might make using external programs unnecessary. Using built-in methods reduces dependencies and makes your code much faster.\nA simple example would be using built-in parameter expansions rather than sed/awk for trivial data manipulation tasks.\n  use #!/bin/sh (or #!/bin/bash, if you need to write shell scripts with bash-isms) as the shebang\nIf a platform doesn\u0026rsquo;t have /bin/sh or /bin/bash (NixOS, BSDs), adapt your scripts accordingly at the time of installation.\nAlthough #!/usr/bin/env sh is better for portability, we\u0026rsquo;ll prefer not to use it. You can\u0026rsquo;t pass arguments in this form and using it allows the possibility of using arbitrary binaries available in PATH. I guess one has bigger problems to worry about if the PATH on his system can\u0026rsquo;t be trusted.\n  use \u0026quot;${var}\u0026quot; instead of \u0026quot;$var\u0026quot; — the exception to this rule is when using positional parameters like \u0026quot;$1\u0026quot; or special parameters like \u0026quot;$@\u0026quot;\n  when using if-then-else, the then block should preferably contain things you want happening if everything\u0026rsquo;s good rather than error responses\nconsider this block of code and execute it\n#!/bin/bash  # pass isn\u0026#39;t defined deliberately or assume that pass has some invalid # characters like non-alphanumeric characters if [ \u0026#34;$pass\u0026#34; -ge 100 ]; then echo \u0026#34;success\u0026#34; else echo \u0026#34;failed\u0026#34; fi if [ \u0026#34;$pass\u0026#34; -lt 100 ]; then echo \u0026#34;failed\u0026#34; else echo \u0026#34;sucess\u0026#34; fi although both constructs are logically the same, the 2nd construct turns out to be problematic because the else block is executed\n  Avoid This #    \u0026amp;\u0026gt; fille and |\u0026amp; tee\n  select — just use a combination of while, read, case, and if instead\n  until loop\n  $'...' ANSI C style quotes\n  ;\u0026amp; and ;;\u0026amp; terminators in case\n  function keyword to define functions\n  POSIX sh #  bash #  Control Operators #  command1 \u0026amp;\u0026amp; command2 causes command2 to be executed only if command1 exits successfully.\ncommand1 || command2 causes command2 to be executed only if command1 fails.\n! command is true if command is false\nRedirections #  The following table depicts the effect of redirection and piping to a file.\nstdin has the file descriptor 0.\n   syntax terminal stdout terminal stderr file stdout file stderr effect on file     \u0026gt; no yes yes no overwrite   \u0026gt;\u0026gt; no yes yes no append   2\u0026gt; yes no no yes overwrite   2\u0026gt;\u0026gt; yes no no yes append   \u0026gt; file 2\u0026gt;\u0026amp;1 no no yes yes overwrite   \u0026gt;\u0026gt; file 2\u0026gt;\u0026amp;1 no no yes yes append   | tee yes yes yes no overwrite   | tee -a yes yes yes no append   2\u0026gt;\u0026amp;1 | tee yes yes yes yes overwrite   2\u0026gt;\u0026amp;1 | tee -a yes yes yes yes append    You might wonder about the difference between \u0026gt; file 2\u0026gt;\u0026amp;1 and 2\u0026gt;\u0026amp;1 \u0026gt; file. In the first case, you won\u0026rsquo;t get any output on the terminal and both stdout (1) and stderr (2) are redirected to file. However, in the 2nd case, stderr is still shown on the terminal.\nFor understanding the meaning behind a\u0026gt;\u0026amp;b, read this as a is now pointing wherever b is pointing at the moment. Also, a won\u0026rsquo;t stop pointing wherever b was pointing to if b starts pointing anywhere else.\nThis implies that \u0026gt; file 2\u0026gt;\u0026amp;1 means that point stdout to file, and also point stderr to wherever stdout is pointing to (which is file). Similarly, 2\u0026gt;\u0026amp;1 \u0026gt; file implies that point stderr to wherever stdout is poiting to (which is the terminal at this point) and then point stdout to file. stderr will still keep pointing to the terminal though.\nHere\u0026rsquo;s a cheatsheet that\u0026rsquo;ll help as well. A series3 of blog posts have been written as well.\nHere Documents #  You might\u0026rsquo;ve come across segments of code such as\nvar=1 cat \u0026lt;\u0026lt; EOF first line second line third line this is a $var EOF cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; first line second line third line this is a $var EOF cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; | sed \u0026#39;s/a/b/\u0026#39; | tee /tmp/foobar foo bar baz EOF if true; then cat \u0026lt;\u0026lt;- EOF \u0026gt; /tmp/yourfilehere The leading tab is ignored. EOF fi These are called here documents. The first form will expand the $var and the second form won\u0026rsquo;t. The third form is meant to demonstrate that the output can be redirected to another command. The final form is used for stripping leading tab characters in cases when here documents are indented for readability purposes.\nConditional Constructs #  Conditional Expression #  The conditional expression [[ \u0026lt;expression\u0026gt; ]] returns a value of 0 or 1 depending on the evaluation of the expression inside.\nA list of common tests you can do inside [[ ... ]] are\n   Operator Syntax Description     -e file TRUE, if file exists   -f file TRUE, if a regular file exists   -d file TRUE, if a directory exists   -r, -w, -x file TRUE, if read, write, executable permissions exist   -s file TRUE, if size of the file is greater than 0 (not empty)   file1 -nt file2 TRUE, if file1 is newer than file2; use -ot for the antonym   -z string TRUE, if string is empty   -n string TRUE, if string is not empty   string1 == string2 TRUE, if string1 matches the pattern in string2   string1 == \u0026quot;string2\u0026quot; TRUE, if string1 literally matches string2   string1 != string2 TRUE, if string1 doesn\u0026rsquo;t match the pattern in string2   string1 =~ string2 TRUE, if string1 matches the extended regex pattern in string2   string1 \u0026lt; string2 TRUE, if string1 sorts before string2   int1 -eq int2 TRUE, if both integers are identical; -ne for the antonym   int1 -lt int2 TRUE, if int1 is less than int2; -gt for the antonym   int1 -le int2 TRUE, if int1 is less than or equal to int2; -ge for the antonym    FILE=\u0026#34;/home/triton/.bashrc\u0026#34; REGEX=\u0026#39;\\/[a-z]*\\/[a-z]*\u0026#39; A=1 B=2 if [[ -f \u0026#34;${FILE}\u0026#34; ]]; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;exists!\u0026#39; fi # no reason not to use quotes here as well when writing variables if [[ \u0026#34;${A}\u0026#34; -eq \u0026#34;${B}\u0026#34; ]]; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;equals!\u0026#39; else printf \u0026#39;%s\\n\u0026#39; \u0026#39;not equal\u0026#39; fi # notice the difference between the following if-else statements # in the 1st case, \u0026#34;${FILE}\u0026#34; matches against a pattern # in the 2nd case, \u0026#34;${FILE}\u0026#34; matches against an exact string if [[ \u0026#34;${FILE}\u0026#34; == \\/[a-z]* ]]; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;matches\u0026#39; else printf \u0026#39;%s\\n\u0026#39; \u0026#39;does not match\u0026#39; fi if [[ \u0026#34;${FILE}\u0026#34; == \u0026#34;\\/[a-z]*\u0026#34; ]]; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;matches\u0026#39; else printf \u0026#39;%s\\n\u0026#39; \u0026#39;does not match\u0026#39; fi # it\u0026#39;s better to use regexes and specifying the regexes in a separate variable # the in-built BASH_REMATCH array variable records the part of the string that # matched the regex if [[ \u0026#34;${FILE}\u0026#34; =~ $REGEX ]]; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;matches\u0026#39; else printf \u0026#39;%s\\n\u0026#39; \u0026#39;does not match\u0026#39; fi echo \u0026#34;${BASH_REMATCH[@]}\u0026#34; if then else #  MOZ_ENABLE_WAYLAND=1 if [[ \u0026#34;${MOZ_ENABLE_WAYLAND}\u0026#34; -eq 1 ]]; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;firefox will run natively in wayland\u0026#39; else printf \u0026#39;%s\\n\u0026#39; \u0026#39;firefox will run in xorg\u0026#39; fi if grep ^triton: /etc/passwd \u0026gt; /dev/null 2\u0026gt;\u0026amp;1; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;triton is orbiting neptune\u0026#39; else printf \u0026#39;%s\\n\u0026#39; \u0026#39;triton has become a rogue satellite\u0026#39; fi if ! mount | grep -i borg \u0026gt;/dev/null 2\u0026gt;\u0026amp;1; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;FATAL: borg backup does not exist\u0026#39; \u0026gt;\u0026amp;2 exit 1 else printf \u0026#39;%s\\n\u0026#39; \u0026#39;borg backup exists and is mounted\u0026#39; fi printf \u0026#39;%s\\n\u0026#39; \u0026#39;enter a number\u0026#39; read -r n if [[ \u0026#34;${n}\u0026#34; -eq 1 ]]; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;value of n is 1\u0026#39; elif [[ \u0026#34;${n}\u0026#34; -eq 2 ]]; then printf \u0026#39;%s\\n\u0026#39; \u0026#39;value of n is 2\u0026#39; else printf \u0026#39;%s\\n\u0026#39; \u0026#39;value of n is other than 1 and 2\u0026#39; fi case #  The elif clause can be written multiple times. However, if you find yourself writing multiple elif clauses, it\u0026rsquo;s better to use case.\nprintf \u0026#39;%s\\n\u0026#39; \u0026#39;locale?\u0026#39; read -r LANG case $LANG in en*) printf \u0026#39;%s\\n\u0026#39; \u0026#39;Hello!\u0026#39; ;; fr*) printf \u0026#39;%s\\n\u0026#39; \u0026#39;Salut!\u0026#39; ;; de*) printf \u0026#39;%s\\n\u0026#39; \u0026#39;Guten Tag!\u0026#39; ;; nl*) printf \u0026#39;%s\\n\u0026#39; \u0026#39;Hallo!\u0026#39; ;; it*) printf \u0026#39;%s\\n\u0026#39; \u0026#39;Ciao!\u0026#39; ;; es*) printf \u0026#39;%s\\n\u0026#39; \u0026#39;Hola!\u0026#39; ;; C | POSIX) printf \u0026#39;%s\\n\u0026#39; \u0026#39;hello world\u0026#39; ;; *) printf \u0026#39;%s\\n\u0026#39; \u0026#39;I do not speak your language.\u0026#39; ;; esac printf \u0026#39;%s\\n\u0026#39; \u0026#39;enter a number\u0026#39; read -r num case \u0026#34;${num}\u0026#34; in \u0026#39;\u0026#39; | *[!0-9]*) printf \u0026#39;%s\\n\u0026#39; \u0026#39;input is not a number\u0026#39; ;; *) printf \u0026#39;%s\\n\u0026#39; \u0026#39;you have entered a number\u0026#39; ;; esac Looping Constructs #  count=10 i=20 ucount=20 j=10 array=(\u0026#34;1\u0026#34; \u0026#34;2\u0026#34; \u0026#34;3\u0026#34; \u0026#34;4\u0026#34; \u0026#34;5\u0026#34;) # while loop while [[ $i -gt $count ]]; do printf \u0026#39;%s\\n\u0026#39; \u0026#34;$i\u0026#34; i=$((i - 1)) done # while loop with negation - use this instead of \u0026#39;until\u0026#39; loop while ! [[ $j -gt $ucount ]]; do printf \u0026#39;%s\\n\u0026#39; $j j=$((j + 1)) done # for loop - 1st form for k in \u0026#34;${array[@]}\u0026#34;; do printf \u0026#39;%s\\n\u0026#39; \u0026#34;$k\u0026#34; done # for loop - arithmetic expression for ((l = 1; l \u0026lt; 10; l++)); do printf \u0026#39;%s\\n\u0026#39; \u0026#34;$l\u0026#34; done In the case of for loops with the arithmetic expression form, if any of the expressions is omitted, it evaluates to 1.\nIn all of these loops, the exit status is the last command executed in the loop.\nThe break and continue builtin commands maybe used to control loop execution.\nGroup Commands #  We can group, and execute, multiple commands using either (list) or { list; }.\nThe former grouping method, (list), creates a subshell. Anything that affects the environment, variables, cd etc., aren\u0026rsquo;t reflected outside the subshell.\nFILE=sample { echo $FILE; } { echo \u0026#34;$FILE\u0026#34; echo \u0026#34;he finally got it\u0026#34; } ( # will be successful echo $FILE FILE1=sample1 # will be successful echo $FILE1 ) # will NOT be successful echo $FILE1 Functions #  Functions, as one might expect, make the code more readable and allow us to reuse code blocks with slightly different arguments.\nopen() { case \u0026#34;$1\u0026#34; in *.mp3|*.ogg|*.wav|*.flac|*.wma) mpv \u0026#34;$1\u0026#34;;; *.jpg|*.gif|*.png|*.bmp) gwenview \u0026#34;$1\u0026#34;;; *.avi|*.mpg|*.mp4|*.wmv) mpv \u0026#34;$1\u0026#34;;; esac } for file; do open \u0026#34;$file\u0026#34; done When a function is executed, the arguments given become positional parameters. The name of the function is the first element of FUNCNAME while the function is executing.\nParameters #  Builtin Commands #  Several built-in commands are used to assist in declaration, I/O, control, and configuration.\nDeclaration Commands #   declare local set and unset shift readonly eval export  I/O #   read mapfile coproc printf echo  Misc #   exec trap wait  Builtin Shell Variables #   https://wiki.ubuntu.com/DashAsBinSh\n  C\u0026rsquo;mon, who uses white spaces in file and directory names in Linux? Okay, I know I don\u0026rsquo;t but not everyone is averse to using white spaces in file and directory names, especially people who come from a Windows background.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n You can still write sh compatible scripts while using bash if you use set -o posix. Or, just install dash, symlink /bin/sh to it, and use #!/bin/sh.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Part 1, Part 2, and Part 3.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:2,href:'/wiki/docs/devops/git/getting-started-with-git/',title:"Getting Started With Git",section:"Git",content:"Instead of rote learning and hoping not to mess up when executing git commands, it\u0026rsquo;s better to understand what\u0026rsquo;s going on under the hood and how git actually works. This guide isn\u0026rsquo;t meant to be a traditional git 101 guide. We\u0026rsquo;ll cover basic terminology briefly but focus solely on git internals because, in my opinion, that\u0026rsquo;s how one should get started with git.\nIntroduction #  There are several insightful one line definitions of what a git repository is but we\u0026rsquo;ll start with this one.\n A git repository is a collection of objects and names for those objects called references or, simply, refs.\n Let\u0026rsquo;s see this for ourselves.\n$ git init repo $ cd repo/ $ tree .git/ .git/ ├── branches ├── HEAD ├── objects │ ├── info │ └── pack └── refs ├── heads └── tags For now, we are concerned with the objects/ and refs/ directories inside .git/. Yes, we\u0026rsquo;ve omitted some output from the tree command to focus on what\u0026rsquo;s important.\nWe usually deal with git using its high level porcelain commands rather than its low level plumbing commands. We\u0026rsquo;ll use the plumbing commands to do a basic operation in git.\nGit Objects #  Let\u0026rsquo;s start by adding something to a git repo.\n$ echo \u0026quot;git internals\u0026quot; | git hash-object -w --stdin 613b11344587e365a3e20af88e29fbaea95cd458 $ tree .git/objects/ .git/objects/ ├── 61 │ └── 3b11344587e365a3e20af88e29fbaea95cd458 ├── info └── pack Notice that we didn\u0026rsquo;t even use a file to store content in git, we just echoed content into the standard input which is received by the git hash-object command which then computes the hexadecimal sha1 hash of the content passed via stdin and stores it in the objects folder.\nOh, if you try to use the sha1sum command on the same input, you won\u0026rsquo;t get the same result. Git appends some meta data about the content that it stores in its objects/ key-value store. You\u0026rsquo;ll need to prefix the type of the object, its size, and a NULL byte to get the same result. You can get the type and size of the object you just stored in the git repo using the git cat-file command.\n$ git cat-file -t 613b11 blob $ git cat-file -s 613b11 14 $ echo -e \u0026quot;blob 14\\0git internals\u0026quot; | sha1sum | tr -d '[:blank:]' | tr -d '-' 613b11344587e365a3e20af88e29fbaea95cd458 This brings us to the fundamental object used by git to store data — blobs. Git stores the contents of files in objects called blobs, binary large objects. The difference between a blob and a file is that a file also contains meta data. For example, a file “remembers” when it was created, so if you move that file into another directory, its creation time remains the same. A blob, on the other hand, is just content — binary streams of data. A blob doesn\u0026rsquo;t register its creation date, its name, or anything but its content.\nAs seen above, we can compute the sha1 hash of the blob that the git computes using the format \u0026quot;blob ${#CONTENTS}\\0$CONTENTS\u0026quot;.\nWhat now?\n$ git status On branch master No commits yet nothing to commit (create/copy files and use \u0026quot;git add\u0026quot; to track) Git doesn\u0026rsquo;t know anything about the object we just created because there\u0026rsquo;s nothing inside our working directory, the directory where your actual content should be. The blob we created is also not present in the staging area aka index yet. Let\u0026rsquo;s add it to the staging area.\n$ git update-index --add --cacheinfo 100644,613b11344587e365a3e20af88e29fbaea95cd458,git-internals.txt $ git status On branch master No commits yet Changes to be committed: (use \u0026quot;git rm --cached \u0026lt;file\u0026gt;...\u0026quot; to unstage) new file: git-internals.txt Changes not staged for commit: (use \u0026quot;git add/rm \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git restore \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) deleted: git-internals.txt This is interesting. We\u0026rsquo;ve added the file git-internals.txt into the staging area but since that file isn\u0026rsquo;t present in the working directory, git thinks that it has been deleted. However, in reality, that file has never been there in the working directory to begin with. We\u0026rsquo;ll come back to this issue later so just forget about it for now. After all, we\u0026rsquo;re dealing with the git repository here, not its working directory and since a git repository is a content addressable storage and a key-value store, if we have the required objects, we can get the required files.\nRemember that we said that blobs are simply content and nothing else? Git stores the meta data of blobs into another fundamental storage unit called a tree object.\n$ git write-tree c19878e8ba21805cc916151c15ba14f9e83d2cd9 $ git cat-file -t c19878 tree $ git cat-file -p c19878 100644 blob 613b11344587e365a3e20af88e29fbaea95cd458	git-internals.txt If you read the man page of git write-tree, you\u0026rsquo;ll see that it mentions that it \u0026ldquo;creates a tree object using the current index\u0026rdquo;. The tree object stores the meta data of blobs and other trees. This meta data includes the file mode, type of object, the sha1 hash of the object, and the file or directory name.\nIf you notice the contents of the .git/ directory now, it\u0026rsquo;ll be something like this:\n$ tree .git/objects/ .git/objects/ ├── 61 │ └── 3b11344587e365a3e20af88e29fbaea95cd458 ├── c1 │ └── 9878e8ba21805cc916151c15ba14f9e83d2cd9 ├── info └── pack The objects/ directory now contains another entry for the tree object. At this point, the output of git status will remain unchanged.\nLet\u0026rsquo;s go ahead and create another fundamental storage unit, the commit object.\n$ git commit-tree -m \u0026quot;first commit\u0026quot; c19878 cc219e7bb9a8275759ba1bfd7e4510bc2e6ff1d1 $ tree .git/objects/ .git/objects/ ├── 61 │ └── 3b11344587e365a3e20af88e29fbaea95cd458 ├── c1 │ └── 9878e8ba21805cc916151c15ba14f9e83d2cd9 ├── cc │ └── 219e7bb9a8275759ba1bfd7e4510bc2e6ff1d1 ├── info └── pack $ git cat-file -t cc219e commit $ git cat-file -p cc219e tree c19878e8ba21805cc916151c15ba14f9e83d2cd9 author Ayush Agarwal \u0026lt;email@email.com\u0026gt; 1608903575 +0530 committer Ayush Agarwal \u0026lt;email@email.com\u0026gt; 1608903575 +0530 first commit As shown in the output of the git cat-file command, the commit object stores the meta data of the tree object, the author, the committer, the time at which the commit was done, and the commit message. Since this is the first commit in our repository, this commit object doesn\u0026rsquo;t point to a parent commit object yet.\nWhile a tree represents a particular directory state of the working directory, a commit represents that state in \u0026ldquo;time\u0026rdquo;, and explains how to get there. Think of a commit object as a snapshot of your working directory at a point in time. When we use the porcelain commands of git, we usually interact with commit objects and their sha1 hashes.\nYou might notice something strange though.\n$ git status On branch master No commits yet Changes to be committed: (use \u0026quot;git rm --cached \u0026lt;file\u0026gt;...\u0026quot; to unstage) new file: git-internals.txt Changes not staged for commit: (use \u0026quot;git add/rm \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git restore \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) deleted: git-internals.txt git status still doesn\u0026rsquo;t think that we\u0026rsquo;ve committed anything yet. There\u0026rsquo;s also the issue of the missing file in our working directory which git thinks has been deleted.\nWe\u0026rsquo;ve finally arrived at the refs/ folder.\nGit References #  Remember that we said that a git repository is a key-value store? Well, the store is the .git/objects/ directory and the keys are in the .git/refs/ directory. In git terminology, values are objects and references are keys. References can be anything from a local branch, a remote branch, an immutable tag, and a file called HEAD which stores a symbolic reference (reference to another reference) unless you\u0026rsquo;re in a detached HEAD state and HEAD then contains a sha1 hash as its reference. This also shows that the sha1 commit hashes can themselves be used as references.\nBy default, a git repository starts with a local branch called master. Let\u0026rsquo;s see what the .git/HEAD file contains.\n$ cat .git/HEAD ref: refs/heads/master The .git/HEAD file just contains a symbolic reference to the master branch. The location of the master branch should be familiar - it\u0026rsquo;s inside the .git/refs/heads/ folder. All we need is a file called master which points to the sha1 hash of the commit object that we made a few minutes ago.\n$ echo \u0026quot;cc219e7bb9a8275759ba1bfd7e4510bc2e6ff1d1\u0026quot; \u0026gt; .git/refs/heads/master Rather than manually adding the sha1 hash of the commit object, we can also use the git update-ref command to change the value of .git/refs/heads/master in a safer manner.\n$ git update-ref refs/heads/master cc219e Finally, we\u0026rsquo;ve successfully made a commit object.\n$ git status On branch master Changes not staged for commit: (use \u0026quot;git add/rm \u0026lt;file\u0026gt;...\u0026quot; to update what will be committed) (use \u0026quot;git restore \u0026lt;file\u0026gt;...\u0026quot; to discard changes in working directory) deleted: git-internals.txt no changes added to commit (use \u0026quot;git add\u0026quot; and/or \u0026quot;git commit -a\u0026quot;) $ git log commit cc219e7bb9a8275759ba1bfd7e4510bc2e6ff1d1 (HEAD -\u0026gt; master) Author: Ayush Agarwal \u0026lt;email@email.com\u0026gt; Date: Fri Dec 25 19:09:35 2020 +0530 first commit To get a clean git status output, we\u0026rsquo;ll add the git-internals.txt file by getting it from git to demonstrate that a git repository ensures the data integrity of your working directory using commit objects.\n$ git checkout git-internals.txt This command retrieves the file git-internals.txt from the staging area and writes it in the working directory. We can write a specific commit object hash before the file name to checkout the version of the file in that commit object.\ngit status is now finally clean and shows us the expected output.\n$ git status On branch master nothing to commit, working tree clean Just for the sake of reference (pun not intended), we would\u0026rsquo;ve used the following porcelain commands to achieve the same result.\n$ git init repo $ cd repo/ $ echo \u0026quot;git internals\u0026quot; \u0026gt; git-internals.txt $ git add git-internals.txt $ git commit -m \u0026quot;first commit\u0026quot; The git add command adds the git-internals.txt file to the staging area and creates the blob object and adds it to the .git/objects/ folder. The git commit command creates a tree object, points it to the blob object, creates a commit object which points to the tree object it just created, and updates the .git/refs/heads/master file with the sha1 hash of the commit object it creates.\nThis is it. You now know the basics of how a git repo actually works under the hood. However, we can still dive in a bit more.\nVisualizing Git #  Let\u0026rsquo;s create another file and another commit object.\n$ echo \u0026quot;git internals v2\u0026quot; \u0026gt; git-internals-v2.txt $ git add git-internals-v2.txt $ git commit -m \u0026quot;second commit\u0026quot; [master 11e5833] second commit 1 file changed, 1 insertion(+) create mode 100644 git-internals-v2.txt $ git log --oneline --decorate --graph --all * 11e5833 (HEAD -\u0026gt; master) second commit * cc219e7 first commit In simple visual terms, all we\u0026rsquo;ve done is create this directed acyclic graph:\n  However, let\u0026rsquo;s see what our repo looks like when we represent all the git objects and references.\n  It should be clear from this diagram that branches are just references that are pointers to commit objects. This pointer moves automatically throughout the graph as you commit more objects and perform other operations.\n$ git checkout -b test $ git log --oneline --decorate --graph --all * 11e5833 (HEAD -\u0026gt; test, master) second commit * cc219e7 first commit $ echo \u0026quot;branches\u0026quot; \u0026gt;\u0026gt; git-internals.txt $ git commit -am \u0026quot;third commit\u0026quot; [test c4691ec] third commit 1 file changed, 1 insertion(+) $ git log --oneline --decorate --graph --all * c4691ec (HEAD -\u0026gt; test) third commit * 11e5833 (master) second commit * cc219e7 first commit Now, check the contents of the .git/refs directory.\n$ tree .git/refs/ .git/refs/ ├── heads │ ├── master │ └── test └── tags $ cat .git/refs/heads/test c4691ec4ee1a3c9fa257cfac16192dbc022c8b9a Where does HEAD point to?\n$ cat .git/HEAD ref: refs/heads/test As we can see, right now, HEAD is symbolic reference to the test branch.\nQuestions #  Here are some questions that you might have come up with while reading this article:\n  Why does git use a tree object? Couldn\u0026rsquo;t we store the meta data stored by the tree object in the commit object?\nOne of the reasons that git uses tree objects is that they help in preserving the working directory structure. Tree objects can store other tree objects which basically represent directories and subdirectories in a working directory. Tree objects represent a snapshot of the working directory at a point in time when a commit object is made.\nAnother reason is that different commits can have the same tree objects. If you followed along with the commands in this guide verbatim, your git repo would have the same (the sha1 hashes would be identical) blob and tree object as I did. However, your commit object sha1 hash will be different than mine because of different meta data like the name and email of the author and committer. In case git encounters the same tree object in different commits in a single repository, it won\u0026rsquo;t create new blob and tree objects and reuse the ones we already have which saves space and increases efficiency.\n  Why does git use the first two characters of the 40-digit hash of git objects as directory names and the remaining 38-digits as the file name of the object itself?\nThe layout of subdirectories in .git/objects/ is in the form of [0-9a-f][0-9a-f]/[0-9a-f]+ which means that there can be 256 subdirectories in .git/objects/. Some file systems like FAT32 can have only 65,536 files in a directory but, technically, there can be 2^60 sha1 hashes. ext2 has performance issues post 10k files in a directory. ext4 doesn\u0026rsquo;t any such limits but it\u0026rsquo;s still limited by the number of inodes it can have.\nIn essence, this directory structure is the result of optimization keeping in mind the performance limitations of file systems.\n  References #  Here are some resources that might help you get started with and understand git. This includes comprehensive references as well. References specific to a certain topic will be included elsewhere.\n Think Like a Git Git From The Bottom Up Git From The Inside Out Chapter 10 of the Pro Git Book  Here are some videos that use git internals to explain how git works.1\n Git From the Bits Up Dissecting Git Guts Advanced Git: Graphs, Hashes, and Compression, Oh My!  Visualizing a git repository and its graph can become easier using:\n this tool this tool which can help you visualize various operations on a git repository gitDAGs LaTeX package might come in handy to draw git graphs. There are instructions on how to install it here. Yeah, I know, LaTeX. But unfortunately, I haven\u0026rsquo;t found anything that looks better than this yet. Mermaid support for git graphs is experimental and looks shabby as of Dec 2020. Please let me know if you find something better. you can use software like gitg and the gitgraph vscode extension to view pretty graphs of your repos.  These resources might help you as well. I haven\u0026rsquo;t completed studying them myself though.\n Git Internals by Scott Chacon A Visual Guide to Git Internals The chapter on Git in the AOSA book Git Magic Git From the Inside Out Chapter 4. Basic Git Concepts    If you like these videos, consider saving them off-line. In my opinion, YouTube cannot be relied upon for data availability.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   "}),a.add({id:3,href:'/wiki/docs/sysadmin/rants/linux/',title:"Linux Desktop Is a Shit Show",section:"Rants",content:"Doing The Unusual — Criticising Linux #  These are the collection of my gripes and frustrations I\u0026rsquo;m either facing right now, or have faced in the past, when using the Linux, or GNU/Linux if you will, on the desktop. I\u0026rsquo;ve been using Linux on my desktop exclusively since 2015 instead of Windows 10 or MacOS.\nFor people out there who\u0026rsquo;re pedantic and radicalized enough to miss the point of the article, this isn\u0026rsquo;t just about the Linux kernel itself but about using Linux ecosystem on a desktop. I don\u0026rsquo;t think you can use the Linux kernel itself on your desktop to do anything meaningful.\nPeople on Reddit and other online communities see Linux as this perfect panacea of user freedom, customization, and power. The shilling never stops and unsuspecting users are led to believe that Microsoft and Apple are sitting on their asses and doing nothing on their desktops while a community of open source developers are doing something better. They fail to mention things like Linux is still stuck with the ancient display server called Xorg which has been called a security circus, Wayland is NOT a daily driver yet (as on April 2021) even if a prominent developer calls people who can\u0026rsquo;t use Wayland as anti vaxxers. I mean, VSCode doesn\u0026rsquo;t work as expected on Wayland yet. It runs on XWayland and becomes blurry if you do fractional scaling, which has become pretty much ubiquitous. Is every dev out there who doesn\u0026rsquo;t use Wayland because of this an anti-vaxxer?\nArguments Made By Linux Enthusiasts #  Oh, one of the most widely used counter arguments that you\u0026rsquo;ll come across when criticising Linux or OSS is this\n In the case of Wayland, the “vague authority” are a bunch of volunteers who have devoted tens of thousands of hours of their free time towards making free shit for you.\n Linux and OSS defenders will say, \u0026ldquo;Hey, they\u0026rsquo;re making it free. Either be grateful or fuck off. You don\u0026rsquo;t get to complain asshole.\u0026quot; If only they said this on their websites or when raving about it everywhere. \u0026ldquo;It works perfectly for me. But if it doesn\u0026rsquo;t work for you after you devote hundreds of hours installing it and learning it, fuck you. You don\u0026rsquo;t get to complain.\u0026quot;\n Maybe Wayland doesn’t work for your precious use-case. More likely, it does work, and you swallowed some propaganda based on an assumption which might have been correct 7 years ago.\n I guess VSCode not working for me and being blurry on my 4k monitor with fractional scaling is propaganda. Apparently, some people\u0026rsquo;s jobs and livelihood depend on this but no, Linux and OSS defenders will pretend that your problems are a niche use case that no one cares about. Besides, you should just be using (neo)vim or emacs instead of VSCode anyways.\n We’ve sacrificed our spare time to build this for you for free. If you turn around and harass us based on some utterly nonsensical conspiracy theories, then you’re a fucking asshole.\n If you go around proselytizing Wayland and sway or some other OSS software and call it \u0026ldquo;stable\u0026rdquo; and \u0026ldquo;ready for daily use\u0026rdquo; and then basic shit like VSCode and Firefox doesn\u0026rsquo;t work as expected, perhaps you\u0026rsquo;re the asshole for wasting people\u0026rsquo;s time by baiting them to switch from their established workflows.\nSince the praise for Linux, and criticism for anyone who speaks otherwise, never stops and no one bothers to highlight serious issues with the Linux desktop, this is my attempt to do so.\nList of Issues #  Not Fixed Yet #    suspend and resume have been buggy and broken on my Intel Haswell desktop since the past 2+ years and on my Thinkpad E495 AMD Ryzen 3500U laptop since I bought it\nThere\u0026rsquo;s no guarantee that my desktop or laptop will come back online if I suspend them. Well, the system does come online but the screen remains turned off and the CPU usage often spikes to 100%. I have no option at that point but to reboot forcibly and lose any potential data. When I asked for help on the Arch forums, I was told to stop whining and compile my own kernel with patches found on gitlab which the dev himself called hacks.\nLet\u0026rsquo;s see how many years it takes for this bug to be fixed. I\u0026rsquo;ll keep adding logs whenever I face an unsuccessful resume.\nIf anyone\u0026rsquo;s interested, here are the logs after an unsuccessful resume and here\u0026rsquo;s one with a successful resume with kernel version 5.10.23.\n  [17th May 2021] Since the past few weeks, my Thinkpad E495 with AMD 3500U CPU keeps crashing in the middle of my work and I have to do hard reboots. This is most probably an AMDGPU issue, going back all the way to 2018 or maybe earlier. But hey, I\u0026rsquo;m not supposed to complain. What\u0026rsquo;s more, if you do complain, people will just say \u0026ldquo;it works like a charm for me\u0026rdquo; and try to make it either your fault or say that your hardware is faulty.\nSeriously, I can\u0026rsquo;t reproduce it but it happens enough that I sometimes want to flip my table. I tried using the LTS kernel 5.10.23 to 5.10.41 but that\u0026rsquo;s basically broken. I get stack traces, page faults, and system freezes almost everyday. This also happened in 5.11.x but lesser than 5.10.x. Switching to 5.12.x made this problem infrequent but it\u0026rsquo;s still there.\nHere are logs with kernel version 5.12.6.\nHere are logs with kernel version 5.12.8.\nI don\u0026rsquo;t know but this looks like a AMDGPU issue to me. People rave about how Nvidia is bad for Linux and how AMD is good because they have open source drivers and how everything works \u0026ldquo;perfectly\u0026rdquo; for them but apparently, basic functionalities like suspend and resume is broken and your system will keep crashing randomly in the middle of work.\nShould I restrict my purchases to Intel only in the future? I asked around and people said that the same problem exists for them on their Intel laptops for as long as they can remember.\n  (neo)vim uses its own ancient spelling dictionaries and, apparently, you can\u0026rsquo;t use hunspell or nuspell with it\nPeople are bickering about replacing apparently the second biggest source code file in Vim, known as spell.c, instead of coming up with a solution. Meanwhile, if you activate (neo)vim\u0026rsquo;s spell check right now, it\u0026rsquo;ll show aren't and didn't as spelling mistakes.\n  (neo)vim can\u0026rsquo;t do syntax highlighting correctly, even with plugins, for a lot of things including gitconfig files and markdown documents.\nThe markdown syntax highlighting library from plasticboy is abandoned and full of bugs. I tried using vim-pandoc-syntax along with its syntax package and that turned out to be similarly buggy and extremely slow.\nHere\u0026rsquo;s a preview of what I\u0026rsquo;m talking about when using vim-pandoc. The same issue happens with vim-markdown.\nWhen people rave about vim, they should mention that if you want to do common stuff like write documentation using markdown, you\u0026rsquo;ll be disappointed.\nAlthough there are ongoing efforts to integrate tree-sitter in neovim, I\u0026rsquo;m not sure how they\u0026rsquo;ll work out. I know, I know, you\u0026rsquo;re using neovim 0.5.0 nightly and it works \u0026ldquo;perfectly\u0026rdquo; for you and it has zero bugs and it can launch humans into space and all that shit. I\u0026rsquo;m not interested.\n  sometimes, pop up menus in Firefox aren’t visible after I right click on something\nThis is incredibly annoying. Sometimes I end up clicking something which I didn’t intend to.\n  apparently, some websites will tell you that the NERDTree plugin made for (neo)vim is bloat and you should just use the built in netrw instead. I guess they fail to mention bugs like this. Hey, for all I know, NERDTree is indeed bloat and shitty.\n  Fixed After Considerable Distress #    when I upgraded to Firefox 87, I experienced intense flickering on pop menus\nAlthough this issue has been fixed in sway version 1.6, I had to downgrade and keep Firefox at version 86 for almost a month after version 87 was released.\n  when waking up my laptop from sleep, Firefox almost always became blurry\nThis happened with fractional scaling enabled. Someone on Reddit told me that this was because of this bug. I’ve been saving my session and restarting Firefox each and every time I came back home, resumed my laptop back from sleep, and tried to start doing my work. Apparently, this issue might’ve been fixed in sway 1.6 but I’ve been dealing with this for many weeks now.\n  "}),a.add({id:4,href:'/wiki/docs/sysadmin/tools/tmux/',title:"tmux",section:"Tools",content:"Basics #  To find out the default value of an option, use the command\n$ tmux show -g \u0026lt;option\u0026gt; Attach and Detach #  You can specify session names using\n$ tmux new -s first You can attach to that particular session later using\n$ tmux attach -t first To create a new session,\n$ tmux new -d -P -s 1 or simply use :new from the tmux status line.\nTo cycle between sessions, use C-s ().\nTo list the available sessions,\n$ tmux ls To list the available keybindigs, use C-s ?.\nUse C-s / + \u0026lt;key\u0026gt; to get a description about what the key does.\nTabs (or Windows) and Split Terminals (or Panes) #  Create new tabs using C-s c.\nCreate a new directionally horizontal split using either\n C-s %, or C-s : + sp -h  A directionally vertical split can be made by using either\n C-s \u0026quot;, or C-s : + sp -v  You can move through open tabs using C-s [0-9]. A custom index can be entered using C-s '. Use n to move to the next tab, p to go to the previous tab, and l to go back and forth.\nYou can move around panes by using C-s ←/→/↑/↓. If you don\u0026rsquo;t want to use arrow keys, press C-s q + \u0026lt;0-9\u0026gt; to select a pane.\nYou can close the current tab (and all of its panes) by pressing C-s \u0026amp;. A single pane can be closed using C-s x.\nYou can temporarily maximize a pane using C-s z and then restore the layout with the same key.\nYou can move tabs by using C-s . and specifying the new index number. Existing index numbers can\u0026rsquo;t be specific though.\n"})})()